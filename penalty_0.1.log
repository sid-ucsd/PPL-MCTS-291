/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loaded discriminator : validation_final_bert_tuned_oracle2024_11_15-06_54_51.pth
loading GPT model
GPT model loaded
loading dataset
dataset loaded
Samples generated:   0%|          | 0/16 [00:00<?, ?it/s]
Tokens generated:   0%|          | 0/10 [00:00<?, ?it/s][A/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py:91: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  tokens_tensor = torch.cuda.LongTensor(tokenizer_res['input_ids'])

Tokens generated:  10%|â–ˆ         | 1/10 [01:20<12:04, 80.53s/it][A
Tokens generated:  20%|â–ˆâ–ˆ        | 2/10 [02:41<10:45, 80.70s/it][A
Tokens generated:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [04:04<09:32, 81.84s/it][A
Tokens generated:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [05:28<08:17, 82.85s/it][A
Tokens generated:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [06:52<06:55, 83.10s/it][A
Tokens generated:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [08:17<05:34, 83.74s/it][A
Tokens generated:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [09:41<04:11, 83.88s/it][A
Tokens generated:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [11:06<02:48, 84.14s/it][A
Tokens generated:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [12:30<01:24, 84.28s/it][A['<|startoftext|> im feeling rather rotten|', '<|startoftext|> im updating my blog im', '<|startoftext|> i never make her make', '<|startoftext|> i left with my left']
['<|startoftext|> im feeling rather rotten|>', '<|startoftext|> im updating my blog im updating', '<|startoftext|> i never make her make her', '<|startoftext|> i left with my left left']
['<|startoftext|> im feeling rather rotten|> im', '<|startoftext|> im updating my blog im updating my', '<|startoftext|> i never make her make her make', '<|startoftext|> i left with my left left|']
['<|startoftext|> im feeling rather rotten|> im feeling', '<|startoftext|> im updating my blog im updating my blog', '<|startoftext|> i never make her make her make her', '<|startoftext|> i left with my left left|>']
['<|startoftext|> im feeling rather rotten|> im feeling rather', '<|startoftext|> im updating my blog im updating my blog im', '<|startoftext|> i never make her make her make her make', '<|startoftext|> i left with my left left|> i']
['<|startoftext|> im feeling rather rotten|> im feeling rather rotten', '<|startoftext|> im updating my blog im updating my blog im updating', '<|startoftext|> i never make her make her make her make her', '<|startoftext|> i left with my left left|> i left']
['<|startoftext|> im feeling rather rotten|> im feeling rather rotten|', '<|startoftext|> im updating my blog im updating my blog im updating my', '<|startoftext|> i never make her make her make her make her make', '<|startoftext|> i left with my left left|> i left with']
['<|startoftext|> im feeling rather rotten|> im feeling rather rotten|>', '<|startoftext|> im updating my blog im updating my blog im updating my blog', '<|startoftext|> i never make her make her make her make her make her', '<|startoftext|> i left with my left left|> i left with my']
['<|startoftext|> im feeling rather rotten|> im feeling rather rotten|> im', '<|startoftext|> im updating my blog im updating my blog im updating my blog im', '<|startoftext|> i never make her make her make her make her make her make', '<|startoftext|> i left with my left left|> i left with my left']
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py", line 590, in <module>
    main()
  File "/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py", line 573, in main
    res_search = MCTS.search(original_input)
  File "/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py", line 363, in search
    self.expand(node_indices, actions, next_node_index)
  File "/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py", line 463, in expand
    (prior, values, next_states) = self._rec_fun(states, tokens_ids, attention_masks, self._labels, self._temperature, self._repetition_penalty)
  File "/teamspace/studios/this_studio/PPL-MCTS/mcts_rollout_emotion.py", line 242, in rec_fun
    while(not is_finished.all() and len(token_ids[0]) < 1024):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py", line 996, in __len__
    def __len__(self):
KeyboardInterrupt
Samples generated:   0%|          | 0/16 [12:31<?, ?it/s]
Tokens generated:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [12:31<01:23, 83.54s/it]
